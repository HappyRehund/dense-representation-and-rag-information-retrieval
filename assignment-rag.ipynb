{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7211618",
   "metadata": {},
   "source": [
    "# RAG System for Sport Articles\n",
    "\n",
    "## Objectives:\n",
    "1. Develop an RAG system using the semantic retriever from the previous assignment\n",
    "2. Evaluate the performance of the RAG system\n",
    "\n",
    "## Pipeline:\n",
    "`Query â†’ Retriever (FAISS) â†’ Retrieved Passages â†’ Prompt Construction â†’ LLM (Ollama) â†’ Grounded Response`\n",
    "\n",
    "## Prerequisites:\n",
    "- Run `assignment-non-rag.ipynb` first to generate embeddings and FAISS index\n",
    "- Start Ollama: `ollama serve`\n",
    "- Pull the model: `ollama pull qwen2.5:7b-instruct`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414f2660",
   "metadata": {},
   "source": [
    "## Step 0: Load Pre-trained Retriever\n",
    "\n",
    "Load the embeddings, FAISS index, and encoder model from the previous assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa4a2a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading encoder model: intfloat/multilingual-e5-base\n",
      "âœ… Loaded 396 articles\n",
      "âœ… Loaded embeddings: (396, 768)\n",
      "âœ… Loaded FAISS index: 396 vectors\n",
      "âœ… Encoder model ready\n",
      "âœ… Loaded 396 articles\n",
      "âœ… Loaded embeddings: (396, 768)\n",
      "âœ… Loaded FAISS index: 396 vectors\n",
      "âœ… Encoder model ready\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Paths\n",
    "DATA_PATH = \"scraping_result/detik_sport_articles_cleaned.json\"\n",
    "EMBEDDINGS_PATH = \"embedding/article_embeddings.npy\"\n",
    "INDEX_PATH = \"faiss/faiss_index.bin\"\n",
    "MODEL_NAME = \"intfloat/multilingual-e5-base\"\n",
    "\n",
    "# Verify files exist\n",
    "required_files = [DATA_PATH, EMBEDDINGS_PATH, INDEX_PATH]\n",
    "for file_path in required_files:\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"âŒ {file_path} not found. Run assignment-non-rag.ipynb first!\")\n",
    "\n",
    "# Load articles data\n",
    "with open(DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    articles = json.load(f)\n",
    "df = pd.DataFrame(articles)\n",
    "df = df[df['content'].str.len() > 50].reset_index(drop=True)\n",
    "\n",
    "# Load embeddings and FAISS index\n",
    "embeddings = np.load(EMBEDDINGS_PATH)\n",
    "index = faiss.read_index(INDEX_PATH)\n",
    "\n",
    "# Load encoder model\n",
    "print(f\"Loading encoder model: {MODEL_NAME}\")\n",
    "encoder_model = SentenceTransformer(MODEL_NAME, device=\"cpu\")\n",
    "\n",
    "print(f\"âœ… Loaded {len(df)} articles\")\n",
    "print(f\"âœ… Loaded embeddings: {embeddings.shape}\")\n",
    "print(f\"âœ… Loaded FAISS index: {index.ntotal} vectors\")\n",
    "print(f\"âœ… Encoder model ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5719b8f6",
   "metadata": {},
   "source": [
    "## Step 1: Select Generation Component\n",
    "\n",
    "### Model Choice: **Qwen2.5:7b-instruct**\n",
    "\n",
    "**Key reasons:**\n",
    "1. **Better Indonesian understanding** - Our articles are in Indonesian\n",
    "2. **Larger context window** - Can include more retrieved passages\n",
    "3. **Better instruction following** - More likely to answer based on context only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "635cc0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ollama is running\n",
      "ğŸ“¦ Available models: ['qwen2.5:7b-instruct']\n",
      "âœ… Model 'qwen2.5:7b-instruct' is available\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Ollama API configuration\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "LLM_MODEL = \"qwen2.5:7b-instruct\"  # or \"qwen2.5:7b\" if instruct not available\n",
    "\n",
    "def check_ollama_status():\n",
    "    \"\"\"Check if Ollama is running and model is available\"\"\"\n",
    "    try:\n",
    "        # Check if Ollama is running\n",
    "        response = requests.get(f\"{OLLAMA_BASE_URL}/api/tags\")\n",
    "        if response.status_code == 200:\n",
    "            models = response.json().get('models', [])\n",
    "            model_names = [m['name'] for m in models]\n",
    "            print(f\"âœ… Ollama is running\")\n",
    "            print(f\"ğŸ“¦ Available models: {model_names}\")\n",
    "\n",
    "            # Check if our model is available\n",
    "            if any(LLM_MODEL in name for name in model_names):\n",
    "                print(f\"âœ… Model '{LLM_MODEL}' is available\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"âš ï¸ Model '{LLM_MODEL}' not found. Please run: ollama pull {LLM_MODEL}\")\n",
    "                return False\n",
    "        else:\n",
    "            print(\"âŒ Ollama API returned error\")\n",
    "            return False\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"âŒ Cannot connect to Ollama. Please start Ollama first: ollama serve\")\n",
    "        return False\n",
    "\n",
    "# Check Ollama status\n",
    "ollama_ready = check_ollama_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f06126",
   "metadata": {},
   "source": [
    "## Step 2: Build RAG Pipeline\n",
    "\n",
    "Components:\n",
    "1. **Retriever**: Reuse FAISS index from Part 1\n",
    "2. **Prompt Constructor**: Combine query + retrieved passages\n",
    "3. **Generator**: Ollama with Qwen2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "898e1be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RAG pipeline functions defined\n"
     ]
    }
   ],
   "source": [
    "def retrieve_passages(query: str, top_k: int = 3) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Retrieve relevant passages using FAISS index.\n",
    "    \"\"\"\n",
    "    # E5 requires \"query: \" prefix\n",
    "    query_with_prefix = f\"query: {query}\"\n",
    "\n",
    "    # Encode query using the encoder model\n",
    "    query_embedding = encoder_model.encode(\n",
    "        [query_with_prefix],\n",
    "        normalize_embeddings=True,\n",
    "        convert_to_numpy=True\n",
    "    )\n",
    "\n",
    "    # Search FAISS\n",
    "    scores, indices = index.search(query_embedding.astype('float32'), top_k)\n",
    "\n",
    "    # Get passages with metadata\n",
    "    passages = []\n",
    "    for score, idx in zip(scores[0], indices[0]):\n",
    "        passages.append({\n",
    "            'title': df.iloc[idx]['title'],\n",
    "            'content': df.iloc[idx]['content'],\n",
    "            'date': df.iloc[idx]['date'],\n",
    "            'score': float(score)\n",
    "        })\n",
    "\n",
    "    return passages\n",
    "\n",
    "\n",
    "def construct_rag_prompt(query: str, passages: list[dict], max_content_len: int = 400) -> str:\n",
    "    \"\"\"\n",
    "    Construct a prompt that combines the query with retrieved passages.\n",
    "    Instructs the LLM to answer based ONLY on the provided context.\n",
    "\n",
    "    Args:\n",
    "        query: User question\n",
    "        passages: Retrieved passages from FAISS\n",
    "        max_content_len: Maximum characters per passage content (default 400 for faster inference)\n",
    "    \"\"\"\n",
    "    # Format passages with shorter content\n",
    "    context_parts = []\n",
    "    for i, p in enumerate(passages, 1):\n",
    "        content_preview = p['content'][:max_content_len]\n",
    "        context_parts.append(f\"[{i}] {p['title']}\\n{content_preview}\")\n",
    "\n",
    "    context = \"\\n\\n\".join(context_parts)\n",
    "\n",
    "    # Shorter, more focused prompt\n",
    "    prompt = f\"\"\"Jawab pertanyaan berdasarkan konteks berikut. Jika tidak ada informasi, katakan \"Tidak tersedia\".\n",
    "\n",
    "KONTEKS:\n",
    "{context}\n",
    "\n",
    "PERTANYAAN: {query}\n",
    "\n",
    "JAWABAN:\"\"\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def construct_non_rag_prompt(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Construct a prompt WITHOUT retrieved passages (for comparison).\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Jawab pertanyaan berikut dalam Bahasa Indonesia.\n",
    "\n",
    "PERTANYAAN: {query}\"\"\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "print(\"âœ… RAG pipeline functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bdf3de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Generation functions defined\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def generate_with_ollama(prompt: str, model: str = LLM_MODEL, timeout: int = 180) -> tuple[str, float]:\n",
    "    \"\"\"\n",
    "    Generate response using Ollama API.\n",
    "\n",
    "    Args:\n",
    "        prompt: The prompt to send to the LLM\n",
    "        model: Ollama model name\n",
    "        timeout: Request timeout in seconds (default 180 = 3 minutes)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (response_text, elapsed_time)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{OLLAMA_BASE_URL}/api/generate\",\n",
    "            json={\n",
    "                \"model\": model,\n",
    "                \"prompt\": prompt,\n",
    "                \"stream\": False,\n",
    "                \"options\": {\n",
    "                    \"temperature\": 0.3,\n",
    "                    \"top_p\": 0.9,\n",
    "                    \"num_predict\": 256\n",
    "                }\n",
    "            },\n",
    "            timeout=timeout\n",
    "        )\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            return response.json()['response'], elapsed\n",
    "        else:\n",
    "            return f\"Error: {response.status_code} - {response.text}\", elapsed\n",
    "    except requests.exceptions.Timeout:\n",
    "        elapsed = time.time() - start_time\n",
    "        return f\"Error: Request timed out after {elapsed:.0f}s. Try a smaller model or shorter context.\", elapsed\n",
    "    except Exception as e:\n",
    "        elapsed = time.time() - start_time\n",
    "        return f\"Error: {str(e)}\", elapsed\n",
    "\n",
    "\n",
    "def rag_query(query: str, top_k: int = 3, verbose: bool = True) -> dict:\n",
    "    \"\"\"\n",
    "    Complete RAG pipeline: Retrieve â†’ Construct Prompt â†’ Generate\n",
    "    \"\"\"\n",
    "    # Step 1: Retrieve relevant passages\n",
    "    passages = retrieve_passages(query, top_k=top_k)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"ğŸ” Query: {query}\")\n",
    "        print(f\"ğŸ“š Retrieved {len(passages)} passages:\")\n",
    "        for i, p in enumerate(passages, 1):\n",
    "            print(f\"   {i}. [{p['score']:.4f}] {p['title']}\")\n",
    "        print()\n",
    "\n",
    "    # Step 2: Construct RAG prompt\n",
    "    rag_prompt = construct_rag_prompt(query, passages)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"ğŸ“Š Prompt: {len(rag_prompt)} chars (~{len(rag_prompt)//4} tokens)\")\n",
    "        print(\"ğŸ¤– Generating RAG response...\")\n",
    "\n",
    "    # Step 3: Generate response\n",
    "    rag_response, elapsed = generate_with_ollama(rag_prompt)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"   â±ï¸ Generated in {elapsed:.1f}s\")\n",
    "\n",
    "    return {\n",
    "        'query': query,\n",
    "        'passages': passages,\n",
    "        'rag_response': rag_response,\n",
    "        'rag_prompt': rag_prompt,\n",
    "        'elapsed': elapsed\n",
    "    }\n",
    "\n",
    "\n",
    "def non_rag_query(query: str, verbose: bool = True) -> dict:\n",
    "    \"\"\"\n",
    "    Generate response WITHOUT retrieval (for comparison)\n",
    "    \"\"\"\n",
    "    prompt = construct_non_rag_prompt(query)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"ğŸ” Query: {query}\")\n",
    "        print(\"ğŸ¤– Generating non-RAG response (no context)...\")\n",
    "\n",
    "    response, elapsed = generate_with_ollama(prompt)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"   â±ï¸ Generated in {elapsed:.1f}s\")\n",
    "\n",
    "    return {\n",
    "        'query': query,\n",
    "        'non_rag_response': response,\n",
    "        'elapsed': elapsed\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"âœ… Generation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd0403f",
   "metadata": {},
   "source": [
    "## Step 3: Evaluation\n",
    "\n",
    "Test the RAG system with different types of questions:\n",
    "1. **Factual queries** - Specific facts that should be in the articles\n",
    "2. **Conceptual understanding** - Questions requiring comprehension\n",
    "3. **Synthesis questions** - Questions requiring combining information from multiple sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b131af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Test Questions Defined:\n",
      "\n",
      "FACTUAL:\n",
      "   1. Siapa pelatih baru Timnas Indonesia?\n",
      "   2. Berapa gol yang dicetak Ronaldo di Piala Dunia 2026?\n",
      "   3. Kapan Barcelona membeli pemain baru terakhir kali?\n",
      "\n",
      "CONCEPTUAL:\n",
      "   1. Mengapa Manchester United mengalami masalah performa musim ini?\n",
      "   2. Apa alasan Rashford kesulitan di Manchester United?\n",
      "   3. Bagaimana kondisi klasemen Liga Inggris saat ini?\n",
      "\n",
      "SYNTHESIS:\n",
      "   1. Bandingkan performa Ronaldo dan pemain bintang lainnya di kompetisi internasional\n",
      "   2. Apa dampak pergantian pelatih terhadap performa tim-tim besar Eropa?\n",
      "   3. Bagaimana situasi transfer pemain di liga-liga top Eropa?\n"
     ]
    }
   ],
   "source": [
    "# Define test questions for different categories\n",
    "test_questions = {\n",
    "    \"factual\": [\n",
    "        \"Siapa pelatih baru Timnas Indonesia?\",\n",
    "        \"Berapa gol yang dicetak Ronaldo di Piala Dunia 2026?\",\n",
    "        \"Kapan Barcelona membeli pemain baru terakhir kali?\"\n",
    "    ],\n",
    "    \"conceptual\": [\n",
    "        \"Mengapa Manchester United mengalami masalah performa musim ini?\",\n",
    "        \"Apa alasan Rashford kesulitan di Manchester United?\",\n",
    "        \"Bagaimana kondisi klasemen Liga Inggris saat ini?\"\n",
    "    ],\n",
    "    \"synthesis\": [\n",
    "        \"Bandingkan performa Ronaldo dan pemain bintang lainnya di kompetisi internasional\",\n",
    "        \"Apa dampak pergantian pelatih terhadap performa tim-tim besar Eropa?\",\n",
    "        \"Bagaimana situasi transfer pemain di liga-liga top Eropa?\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"ğŸ“‹ Test Questions Defined:\")\n",
    "for category, questions in test_questions.items():\n",
    "    print(f\"\\n{category.upper()}:\")\n",
    "    for i, q in enumerate(questions, 1):\n",
    "        print(f\"   {i}. {q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41d0536",
   "metadata": {},
   "source": [
    "### Test 1: Factual Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aceeb0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG: See what's being sent to the LLM (UNTUK DWBUGGING AJA)\n",
    "test_query = \"Siapa pelatih baru Timnas Indonesia?\"\n",
    "passages = retrieve_passages(test_query, top_k=3)\n",
    "rag_prompt = construct_rag_prompt(test_query, passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8fbab15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š PROMPT STATISTICS:\n",
      "   - Total characters: 1540\n",
      "   - Estimated tokens: ~385 tokens\n",
      "   - Number of passages: 3\n",
      "\n",
      "ğŸ“ FULL PROMPT SENT TO LLM:\n",
      "================================================================================\n",
      "Jawab pertanyaan berdasarkan konteks berikut. Jika tidak ada informasi, katakan \"Tidak tersedia\".\n",
      "\n",
      "KONTEKS:\n",
      "[1] Gabung Navbahor, Kapadze Dipastikan Tidak Latih Timnas Indonesia\n",
      "Jakarta - Timur Kapadze dipastikan tidak akan menjadi pelatih Timnas Indonesia . Dia sudah menerima pinangan klub Navbahor Namangan. \"Navbahor hari ini secara resmi memperkenalkan Timur Kapadze sebagai pelatih kepala baru. Kedua pihak telah menandatangani kontrak kerja sama,\" bunyi pernyataan klub di media sosial, Senin . Navbahor adalah klub asal Uzbekistan yang sudah berdiri sejak 1978. Kapadze \n",
      "\n",
      "[2] SEA Games 2025: Timnas Basket Coret 3 Nama\n",
      "Jakarta - Timnas basket Indonesia akan kembali mencoret tiga nama. Itu sebagai bagian dari persiapan mengikuti rangkaian uji coba di Australia menuju SEA Games 2025. Diketahui, Timnas telah menjalani pemusatan latihan sejak 10 September lalu dengan memanggil 24 pemain. Nyaris sebulan berjalan, Pelatih David Singleton kemudian melakukan pengurangan pemain pada 1 Oktober dan kini berjumlah 18 pemain\n",
      "\n",
      "[3] BTN Panggil 24 Pebasket Ikuti TC SEA Games 2025\n",
      "Jakarta - Sebanyak 24 pebasket putra bakal mengikuti training camp menuju SEA Games 2025 . Pemusatan bakal berlangsung mulai Rabu . Badan Tim Nasional Perbasi merilis daftar nama tersebut untuk mengikuti program latihan menuju multiajang olahraga se-Asia Tenggara di Thailand, 9-20 Desember ini. Mereka yang dipanggil merupakan bagian dari pemantauan dari kompetisi Indonesia Basketball League selama\n",
      "\n",
      "PERTANYAAN: Siapa pelatih baru Timnas Indonesia?\n",
      "\n",
      "JAWABAN:\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“Š PROMPT STATISTICS:\")\n",
    "print(f\"   - Total characters: {len(rag_prompt)}\")\n",
    "print(f\"   - Estimated tokens: ~{len(rag_prompt) // 4} tokens\")\n",
    "print(f\"   - Number of passages: {len(passages)}\")\n",
    "print()\n",
    "print(\"ğŸ“ FULL PROMPT SENT TO LLM:\")\n",
    "print(\"=\" * 80)\n",
    "print(rag_prompt)\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f1652ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Query: Siapa pelatih baru Timnas Indonesia?\n",
      "ğŸ“š Retrieved 3 passages:\n",
      "   1. [0.8454] Gabung Navbahor, Kapadze Dipastikan Tidak Latih Timnas Indonesia\n",
      "   2. [0.8248] SEA Games 2025: Timnas Basket Coret 3 Nama\n",
      "   3. [0.8186] BTN Panggil 24 Pebasket Ikuti TC SEA Games 2025\n",
      "\n",
      "ğŸ“Š Prompt: 1540 chars (~385 tokens)\n",
      "ğŸ¤– Generating RAG response...\n",
      "   â±ï¸ Generated in 48.5s\n",
      "ğŸ” Query: Siapa pelatih baru Timnas Indonesia?\n",
      "ğŸ¤– Generating non-RAG response (no context)...\n",
      "   â±ï¸ Generated in 48.5s\n",
      "ğŸ” Query: Siapa pelatih baru Timnas Indonesia?\n",
      "ğŸ¤– Generating non-RAG response (no context)...\n",
      "   â±ï¸ Generated in 16.4s\n",
      "   â±ï¸ Generated in 16.4s\n"
     ]
    }
   ],
   "source": [
    "# Factual Query Test\n",
    "factual_query = \"Siapa pelatih baru Timnas Indonesia?\"\n",
    "\n",
    "# RAG Response\n",
    "factual_rag_result = rag_query(factual_query, top_k=3)\n",
    "\n",
    "# Non-RAG Response\n",
    "factual_non_rag_result = non_rag_query(factual_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beb27703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FACTUAL QUERY TEST\n",
      "================================================================================\n",
      "\n",
      "ğŸ“— RAG RESPONSE:\n",
      "----------------------------------------\n",
      "Pelatih baru Timnas Indonesia adalah Timur Kapadze, yang sekarang menjadi pelatih kepala baru untuk klub Navbahor Namangan di Uzbekistan.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“• NON-RAG RESPONSE:\n",
      "----------------------------------------\n",
      "Maaf, saya tidak memiliki informasi terbaru tentang pelatih tim nasional Indonesia karena data yang saya miliki terbatas dan tidak selalu up-to-date. Untuk mendapatkan informasi terkini mengenai pelatih tim nasional Indonesia, Anda bisa mengunjungi situs resmi PSSI (Persatuan Sepakbola Seluruh Indonesia) atau media berita yang terpercaya.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"FACTUAL QUERY TEST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ“— RAG RESPONSE:\")\n",
    "print(\"-\" * 40)\n",
    "print(factual_rag_result['rag_response'])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ“• NON-RAG RESPONSE:\")\n",
    "print(\"-\" * 40)\n",
    "print(factual_non_rag_result['non_rag_response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc84c22",
   "metadata": {},
   "source": [
    "### Test 2: Conceptual Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44cc449f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Query: Mengapa Rashford kesulitan di Manchester United?\n",
      "ğŸ“š Retrieved 3 passages:\n",
      "   1. [0.8942] Deco: Rashford Menderita di MU\n",
      "   2. [0.8361] Flick: Rashford Enjoy Banget di Barcelona\n",
      "   3. [0.8296] Ruben Amorim Sadar Patrick Dorgu Cemas Tiap Kuasai Bola\n",
      "\n",
      "ğŸ“Š Prompt: 1525 chars (~381 tokens)\n",
      "ğŸ¤– Generating RAG response...\n",
      "   â±ï¸ Generated in 70.3s\n",
      "ğŸ” Query: Mengapa Rashford kesulitan di Manchester United?\n",
      "ğŸ¤– Generating non-RAG response (no context)...\n",
      "   â±ï¸ Generated in 70.3s\n",
      "ğŸ” Query: Mengapa Rashford kesulitan di Manchester United?\n",
      "ğŸ¤– Generating non-RAG response (no context)...\n",
      "   â±ï¸ Generated in 46.9s\n",
      "   â±ï¸ Generated in 46.9s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Conceptual Query Test\n",
    "conceptual_query = \"Mengapa Rashford kesulitan di Manchester United?\"\n",
    "\n",
    "# RAG Response\n",
    "conceptual_rag_result = rag_query(conceptual_query, top_k=3)\n",
    "\n",
    "# Non-RAG Response\n",
    "conceptual_non_rag_result = non_rag_query(conceptual_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "263e807a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CONCEPTUAL UNDERSTANDING TEST\n",
      "================================================================================\n",
      "\n",
      "ğŸ“— RAG RESPONSE:\n",
      "----------------------------------------\n",
      "Menurut konteks yang diberikan, Marcus Rashford kesulitan di Manchester United karena beberapa alasan:\n",
      "\n",
      "1. Dia dipinjamkan oleh Manchester United ke Barcelona pada musim panas lalu.\n",
      "2. Setelah tidak masuk rencana pelatih Ruben Amorim di Barcelona, dia kembali dipinjamkan oleh MU dan ini merupakan kali kedua secara beruntun.\n",
      "\n",
      "Kesulitan Rashford di Manchester United mungkin juga terkait dengan kurangnya waktu bermain yang cukup di bawah naungan Man United akibat pinjaman tersebut.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“• NON-RAG RESPONSE:\n",
      "----------------------------------------\n",
      "Rashford mengalami beberapa masalah yang dapat menyebabkan dia kesulitan di Manchester United, termasuk:\n",
      "\n",
      "1. Tekanan Emosional: Sebagai salah satu pemain muda berbakat dan menjadi bagian penting dari skuad Manchester United sejak usia dini, Rashford sering menghadapi tekanan besar untuk terus memberikan performa yang luar biasa.\n",
      "\n",
      "2. Persaingan Ketat: Manchester United memiliki banyak pemain berkualitas di setiap posisi, dan ini membuat persaingan untuk tempat di tim menjadi sangat ketat. Hal ini bisa menyulitkan Rashford dalam mempertahankan posisinya sebagai starter.\n",
      "\n",
      "3. Performa Variatif: Meskipun dia adalah salah satu striker terbaik Premier League, Rashford pernah mengalami periode performa yang tidak konsisten, yang dapat membuat pelatih meragukan keputusannya untuk memainkan pemain tersebut.\n",
      "\n",
      "4. Cedera: Seperti semua atlet, Rashford juga rawan cedera. Cedera-cedera seringkali bisa mengganggu rutinitas latihan dan pertandingan, yang tentu saja\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"CONCEPTUAL UNDERSTANDING TEST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ“— RAG RESPONSE:\")\n",
    "print(\"-\" * 40)\n",
    "print(conceptual_rag_result['rag_response'])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ“• NON-RAG RESPONSE:\")\n",
    "print(\"-\" * 40)\n",
    "print(conceptual_non_rag_result['non_rag_response'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6400f38c",
   "metadata": {},
   "source": [
    "### Test 3: Synthesis Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3616f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Query: Bagaimana situasi transfer pemain di liga-liga top Eropa?\n",
      "ğŸ“š Retrieved 5 passages:\n",
      "   1. [0.8229] FIFA Izinkan Klub-klub Premier League Telat Lepas Pemainnya ke Piala Afrika\n",
      "   2. [0.8158] Aturan Substitusi: Dari 3 Pemain hingga 5 Pemain\n",
      "   3. [0.8110] Nico Paz Balik ke Real Madrid? Fabregas Kasih Komentar Tajam\n",
      "   4. [0.8103] Szczesny 'Tak Gajian' di Musim Pertamanya di Barca\n",
      "   5. [0.8091] Courtois: Selalu Ada Pemain yang Kurang Bahagia di Ruang Ganti Madrid\n",
      "\n",
      "ğŸ“Š Prompt: 2524 chars (~631 tokens)\n",
      "ğŸ¤– Generating RAG response...\n",
      "   â±ï¸ Generated in 96.7s\n",
      "ğŸ” Query: Bagaimana situasi transfer pemain di liga-liga top Eropa?\n",
      "ğŸ¤– Generating non-RAG response (no context)...\n",
      "   â±ï¸ Generated in 96.7s\n",
      "ğŸ” Query: Bagaimana situasi transfer pemain di liga-liga top Eropa?\n",
      "ğŸ¤– Generating non-RAG response (no context)...\n",
      "   â±ï¸ Generated in 47.8s\n",
      "   â±ï¸ Generated in 47.8s\n"
     ]
    }
   ],
   "source": [
    "# Synthesis Query Test\n",
    "synthesis_query = \"Bagaimana situasi transfer pemain di liga-liga top Eropa?\"\n",
    "\n",
    "# RAG Response\n",
    "synthesis_rag_result = rag_query(synthesis_query, top_k=5)  # More passages for synthesis\n",
    "\n",
    "# Non-RAG Response\n",
    "synthesis_non_rag_result = non_rag_query(synthesis_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8c55a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SYNTHESIS QUESTION TEST\n",
      "================================================================================\n",
      "\n",
      "ğŸ“— RAG RESPONSE:\n",
      "----------------------------------------\n",
      "Tidak tersedia.\n",
      "\n",
      "Konteks yang diberikan tidak menyediakan informasi spesifik tentang situasi transfer pemain di liga-liga top Eropa. Konten tersebut membahas mengenai izin FIFA untuk Premier League, aturan substitusi dalam sepakbola, Nico Paz dan Real Madrid, Szczesny pensiun dari Barcelona, serta ketegangan di ruang ganti Real Madrid. Tidak ada informasi yang spesifik tentang transfer pemain secara umum di liga-liga top Eropa.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“• NON-RAG RESPONSE:\n",
      "----------------------------------------\n",
      "Situasi transfer pemain di liga-liga top Eropa sangat dinamis dan penuh dengan kegiatan. Transfer pemain biasanya terjadi pada musim panas (juni-agustus) dan musim dingin (januari) setiap tahunnya, meskipun ada beberapa pengecualian.\n",
      "\n",
      "1. **Aktivitas Transfensi**: Klub-klub besar di liga-liga top Eropa seperti Premier League Inggris, La Liga Spanyol, Serie A Italia, Bundesliga Jerman, dan Ligue 1 Prancis sering kali melakukan banyak transfer pemain. Transfer ini bisa berupa transfer gratis (pemain yang tidak lagi diperlukan oleh klub asal), transfer dengan biaya jual beli, atau transfer dengan sistem pinjaman.\n",
      "\n",
      "2. **Biaya Transfensi**: Biaya transfer pemain dapat sangat bervariasi, mulai dari beberapa ribu euro hingga ratusan juta euro untuk pemain top dunia. Klub-klub yang memiliki kekayaan finansial lebih besar cenderung melakukan transfer dengan biaya yang lebih tinggi.\n",
      "\n",
      "3. **Kualitas Pemain**: Klub bias\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SYNTHESIS QUESTION TEST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ“— RAG RESPONSE:\")\n",
    "print(\"-\" * 40)\n",
    "print(synthesis_rag_result['rag_response'])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ“• NON-RAG RESPONSE:\")\n",
    "print(\"-\" * 40)\n",
    "print(synthesis_non_rag_result['non_rag_response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6bd974",
   "metadata": {},
   "source": [
    "## Step 4: Qualitative Evaluation Framework\n",
    "\n",
    "Since automated evaluation of RAG systems can be unreliable, we use a **human evaluation framework** with clear criteria.\n",
    "\n",
    "### Evaluation Criteria:\n",
    "\n",
    "| Criterion | Description | Score Range |\n",
    "|-----------|-------------|-------------|\n",
    "| **Groundedness** | Is the answer based on retrieved passages? | 1-5 |\n",
    "| **Factual Accuracy** | Are the stated facts correct? | 1-5 |\n",
    "| **Hallucination** | Does it avoid making up information? | 1-5 |\n",
    "| **Relevance** | Does it answer the question? | 1-5 |\n",
    "| **Completeness** | Is the answer comprehensive? | 1-5 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44472df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comprehensive evaluation on all three test types\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPREHENSIVE EVALUATION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Collect all results\n",
    "all_results = {\n",
    "    \"Factual\": {\n",
    "        \"query\": factual_query,\n",
    "        \"rag\": factual_rag_result,\n",
    "        \"non_rag\": factual_non_rag_result\n",
    "    },\n",
    "    \"Conceptual\": {\n",
    "        \"query\": conceptual_query,\n",
    "        \"rag\": conceptual_rag_result,\n",
    "        \"non_rag\": conceptual_non_rag_result\n",
    "    },\n",
    "    \"Synthesis\": {\n",
    "        \"query\": synthesis_query,\n",
    "        \"rag\": synthesis_rag_result,\n",
    "        \"non_rag\": synthesis_non_rag_result\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display summary table\n",
    "print(\"\\nğŸ“Š Response Time Comparison:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Query Type':<15} {'RAG Time':<15} {'Non-RAG Time':<15}\")\n",
    "print(\"-\" * 60)\n",
    "for qtype, results in all_results.items():\n",
    "    rag_time = results['rag']['elapsed']\n",
    "    non_rag_time = results['non_rag']['elapsed']\n",
    "    print(f\"{qtype:<15} {rag_time:.1f}s{'':<10} {non_rag_time:.1f}s\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Display retrieved passages for each query\n",
    "print(\"\\nğŸ“š Retrieved Passages Summary:\")\n",
    "for qtype, results in all_results.items():\n",
    "    print(f\"\\n{qtype}: {results['query'][:50]}...\")\n",
    "    for i, p in enumerate(results['rag']['passages'], 1):\n",
    "        print(f\"   {i}. [{p['score']:.4f}] {p['title'][:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1087191c",
   "metadata": {},
   "source": [
    "### Manual Evaluation Template\n",
    "\n",
    "Use the cell below to manually score the responses. Fill in scores 1-5 for each criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02c73e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Evaluation Scores (Fill in after reviewing responses above)\n",
    "# Score range: 1 (Poor) to 5 (Excellent)\n",
    "\n",
    "manual_scores = {\n",
    "    \"RAG\": {\n",
    "        \"Factual\": {\n",
    "            \"groundedness\": 0,      # Is answer based on retrieved passages?\n",
    "            \"factual_accuracy\": 0,  # Are facts correct?\n",
    "            \"no_hallucination\": 0,  # Does it avoid making things up?\n",
    "            \"relevance\": 0,         # Does it answer the question?\n",
    "            \"completeness\": 0       # Is the answer complete?\n",
    "        },\n",
    "        \"Conceptual\": {\n",
    "            \"groundedness\": 0,\n",
    "            \"factual_accuracy\": 0,\n",
    "            \"no_hallucination\": 0,\n",
    "            \"relevance\": 0,\n",
    "            \"completeness\": 0\n",
    "        },\n",
    "        \"Synthesis\": {\n",
    "            \"groundedness\": 0,\n",
    "            \"factual_accuracy\": 0,\n",
    "            \"no_hallucination\": 0,\n",
    "            \"relevance\": 0,\n",
    "            \"completeness\": 0\n",
    "        }\n",
    "    },\n",
    "    \"Non-RAG\": {\n",
    "        \"Factual\": {\n",
    "            \"groundedness\": 0,\n",
    "            \"factual_accuracy\": 0,\n",
    "            \"no_hallucination\": 0,\n",
    "            \"relevance\": 0,\n",
    "            \"completeness\": 0\n",
    "        },\n",
    "        \"Conceptual\": {\n",
    "            \"groundedness\": 0,\n",
    "            \"factual_accuracy\": 0,\n",
    "            \"no_hallucination\": 0,\n",
    "            \"relevance\": 0,\n",
    "            \"completeness\": 0\n",
    "        },\n",
    "        \"Synthesis\": {\n",
    "            \"groundedness\": 0,\n",
    "            \"factual_accuracy\": 0,\n",
    "            \"no_hallucination\": 0,\n",
    "            \"relevance\": 0,\n",
    "            \"completeness\": 0\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"ğŸ“ Manual Evaluation Template\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nInstructions:\")\n",
    "print(\"1. Review the RAG and Non-RAG responses from the tests above\")\n",
    "print(\"2. Fill in scores (1-5) in the manual_scores dictionary\")\n",
    "print(\"3. Run the next cell to see the summary\")\n",
    "print(\"\\nScoring Guide:\")\n",
    "print(\"  1 = Poor       - Completely wrong or irrelevant\")\n",
    "print(\"  2 = Below Avg  - Major issues\")\n",
    "print(\"  3 = Average    - Acceptable but with issues\")\n",
    "print(\"  4 = Good       - Mostly correct with minor issues\")\n",
    "print(\"  5 = Excellent  - Fully correct and complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0a536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_evaluation_summary(scores: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate summary statistics from manual evaluation scores.\n",
    "    \"\"\"\n",
    "    criteria = [\"groundedness\", \"factual_accuracy\", \"no_hallucination\", \"relevance\", \"completeness\"]\n",
    "\n",
    "    summary = []\n",
    "    for system in [\"RAG\", \"Non-RAG\"]:\n",
    "        system_scores = scores[system]\n",
    "\n",
    "        # Calculate averages across all queries\n",
    "        avg_scores = {c: [] for c in criteria}\n",
    "\n",
    "        for query_scores in system_scores.values():\n",
    "            for criterion, score in query_scores.items():\n",
    "                if score > 0:  # Only count filled scores\n",
    "                    avg_scores[criterion].append(score)\n",
    "\n",
    "        # Calculate final averages\n",
    "        final_scores = {}\n",
    "        for criterion, scores_list in avg_scores.items():\n",
    "            final_scores[criterion] = sum(scores_list) / len(scores_list) if scores_list else 0\n",
    "\n",
    "        overall = sum(final_scores.values()) / len(final_scores) if any(final_scores.values()) else 0\n",
    "\n",
    "        summary.append({\n",
    "            \"System\": system,\n",
    "            \"Groundedness\": final_scores[\"groundedness\"],\n",
    "            \"Factual Acc.\": final_scores[\"factual_accuracy\"],\n",
    "            \"No Halluc.\": final_scores[\"no_hallucination\"],\n",
    "            \"Relevance\": final_scores[\"relevance\"],\n",
    "            \"Completeness\": final_scores[\"completeness\"],\n",
    "            \"Overall\": overall\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(summary)\n",
    "\n",
    "\n",
    "# Calculate and display summary\n",
    "print(\"ğŸ“Š Evaluation Summary\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check if scores have been filled\n",
    "has_scores = any(\n",
    "    score > 0\n",
    "    for system in manual_scores.values()\n",
    "    for query in system.values()\n",
    "    for score in query.values()\n",
    ")\n",
    "\n",
    "if not has_scores:\n",
    "    print(\"âš ï¸ No scores filled yet. Please fill in manual_scores above and re-run this cell.\")\n",
    "else:\n",
    "    summary_df = calculate_evaluation_summary(manual_scores)\n",
    "    print(summary_df.to_string(index=False))\n",
    "\n",
    "    # Calculate winner for each criterion\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"ğŸ† Winner by Criterion:\")\n",
    "    for col in summary_df.columns[1:]:\n",
    "        rag_score = summary_df.loc[summary_df['System'] == 'RAG', col].values[0]\n",
    "        non_rag_score = summary_df.loc[summary_df['System'] == 'Non-RAG', col].values[0]\n",
    "        if rag_score > non_rag_score:\n",
    "            print(f\"   {col}: RAG wins ({rag_score:.2f} vs {non_rag_score:.2f})\")\n",
    "        elif non_rag_score > rag_score:\n",
    "            print(f\"   {col}: Non-RAG wins ({non_rag_score:.2f} vs {rag_score:.2f})\")\n",
    "        else:\n",
    "            print(f\"   {col}: Tie ({rag_score:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8760ce",
   "metadata": {},
   "source": [
    "## Step 5: RAG System Analysis & Conclusions\n",
    "\n",
    "### How to Evaluate RAG Quality\n",
    "\n",
    "Since automated metrics can be unreliable for RAG evaluation, here are the recommended approaches:\n",
    "\n",
    "#### 1. **Human Evaluation (Most Reliable)**\n",
    "- Have evaluators score responses on the criteria above\n",
    "- Use multiple evaluators and calculate inter-rater agreement\n",
    "- Best for final quality assessment\n",
    "\n",
    "#### 2. **Automated Heuristics (Supplementary)**\n",
    "- Check if response contains keywords from retrieved passages\n",
    "- Measure response length and structure\n",
    "- Detect obvious hallucination patterns (e.g., citing non-existent sources)\n",
    "\n",
    "#### 3. **A/B Testing (Production)**\n",
    "- Compare user satisfaction between RAG and non-RAG\n",
    "- Measure engagement metrics (clicks, time spent)\n",
    "\n",
    "### Expected RAG vs Non-RAG Differences:\n",
    "\n",
    "| Aspect | RAG | Non-RAG |\n",
    "|--------|-----|---------|\n",
    "| **Factual Accuracy** | âœ… Higher (grounded in documents) | âš ï¸ May hallucinate |\n",
    "| **Up-to-date Info** | âœ… Uses recent articles | âŒ Knowledge cutoff |\n",
    "| **Source Attribution** | âœ… Can cite sources | âŒ No sources |\n",
    "| **Domain Specificity** | âœ… Specific to your corpus | âš ï¸ General knowledge |\n",
    "| **Handling Unknown** | âœ… Says \"not in documents\" | âš ï¸ May make up answers |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c2ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple automated heuristic evaluation\n",
    "def automated_heuristics(query: str, rag_response: str, passages: list[dict]) -> dict:\n",
    "    \"\"\"\n",
    "    Simple automated checks (NOT a replacement for human evaluation)\n",
    "    \"\"\"\n",
    "    # Check if response mentions retrieved content\n",
    "    passage_keywords = set()\n",
    "    for p in passages:\n",
    "        # Extract key terms from titles\n",
    "        words = p['title'].lower().split()\n",
    "        passage_keywords.update([w for w in words if len(w) > 3])\n",
    "\n",
    "    response_lower = rag_response.lower()\n",
    "    keyword_mentions = sum(1 for kw in passage_keywords if kw in response_lower)\n",
    "\n",
    "    # Check for \"information not available\" patterns (good sign of not hallucinating)\n",
    "    uncertainty_phrases = [\n",
    "        \"tidak tersedia\", \"tidak ditemukan\", \"tidak ada informasi\",\n",
    "        \"berdasarkan artikel\", \"menurut artikel\", \"dalam konteks\"\n",
    "    ]\n",
    "    shows_uncertainty = any(phrase in response_lower for phrase in uncertainty_phrases)\n",
    "    cites_source = any(phrase in response_lower for phrase in [\"menurut artikel\", \"berdasarkan artikel\", \"dalam artikel\"])\n",
    "\n",
    "    return {\n",
    "        \"keyword_overlap\": keyword_mentions,\n",
    "        \"total_passage_keywords\": len(passage_keywords),\n",
    "        \"shows_appropriate_uncertainty\": shows_uncertainty,\n",
    "        \"cites_sources\": cites_source,\n",
    "        \"response_length\": len(rag_response.split())\n",
    "    }\n",
    "\n",
    "\n",
    "# Test the heuristics\n",
    "test_query = \"Siapa pelatih Timnas Indonesia?\"\n",
    "test_result = rag_query(test_query, top_k=3, verbose=False)\n",
    "\n",
    "heuristics = automated_heuristics(\n",
    "    test_query,\n",
    "    test_result['rag_response'],\n",
    "    test_result['passages']\n",
    ")\n",
    "\n",
    "print(\"ğŸ” Automated Heuristics (Supplementary Only)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Query: {test_query}\")\n",
    "print(f\"\\nHeuristic Results:\")\n",
    "for key, value in heuristics.items():\n",
    "    print(f\"  - {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7acd15",
   "metadata": {},
   "source": [
    "## Summary: RAG System Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                     RAG SYSTEM PIPELINE                        â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                 â”‚\n",
    "â”‚   User Query                                                    â”‚\n",
    "â”‚       â”‚                                                         â”‚\n",
    "â”‚       â–¼                                                         â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚\n",
    "â”‚   â”‚  RETRIEVER (from assignment-non-rag)â”‚                      â”‚\n",
    "â”‚   â”‚  - Multilingual E5 Encoder          â”‚                      â”‚\n",
    "â”‚   â”‚  - FAISS Vector Index               â”‚                      â”‚\n",
    "â”‚   â”‚  - Top-K Similar Documents          â”‚                      â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚\n",
    "â”‚       â”‚                                                         â”‚\n",
    "â”‚       â–¼                                                         â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚\n",
    "â”‚   â”‚  PROMPT CONSTRUCTOR                 â”‚                      â”‚\n",
    "â”‚   â”‚  - Combine Query + Passages         â”‚                      â”‚\n",
    "â”‚   â”‚  - Add Grounding Instructions       â”‚                      â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚\n",
    "â”‚       â”‚                                                         â”‚\n",
    "â”‚       â–¼                                                         â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚\n",
    "â”‚   â”‚  GENERATOR (Ollama)                 â”‚                      â”‚\n",
    "â”‚   â”‚  - Qwen2.5-7B-Instruct              â”‚                      â”‚\n",
    "â”‚   â”‚  - Grounded Response Generation     â”‚                      â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚\n",
    "â”‚       â”‚                                                         â”‚\n",
    "â”‚       â–¼                                                         â”‚\n",
    "â”‚   Grounded Response                                             â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Key Takeaways:\n",
    "1. **RAG improves factual accuracy** by grounding responses in retrieved documents\n",
    "2. **Human evaluation is essential** - automated metrics are supplementary\n",
    "3. **RAG reduces hallucination** when properly instructed to use only context\n",
    "4. **Trade-off**: RAG responses are limited to corpus knowledge\n",
    "\n",
    "### Files Generated:\n",
    "- `assignment-non-rag.ipynb`: Semantic search with FAISS (prerequisite)\n",
    "- `assignment-rag.ipynb`: RAG system with Ollama (this notebook)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-sport-articles (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
