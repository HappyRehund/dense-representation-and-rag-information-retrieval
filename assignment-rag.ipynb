{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7211618",
   "metadata": {},
   "source": [
    "# RAG System for Sport Articles\n",
    "\n",
    "## Objectives:\n",
    "1. Develop an RAG system using the semantic retriever from the previous assignment\n",
    "2. Evaluate the performance of the RAG system\n",
    "\n",
    "## Pipeline:\n",
    "```\n",
    "User Query â†’ LLM Query Understanding â†’ Optimized Query â†’ FAISS (Chunk Retrieval) â†’ Retrieved Chunks â†’ Prompt Construction â†’ LLM Response â†’ Grounded Response\n",
    "```\n",
    "\n",
    "## Key Features:\n",
    "- **Query Understanding**: LLM transforms natural language questions into search-optimized queries\n",
    "- **Chunk-based Retrieval**: FAISS retrieves relevant **chunks** (500 chars with 100 overlap) instead of full articles\n",
    "- **Semantic Search**: Multilingual E5 encoder for Indonesian sports articles\n",
    "- **Grounded Generation**: Qwen2.5 generates responses based on retrieved context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414f2660",
   "metadata": {},
   "source": [
    "## Step 0: Load Pre-trained Retriever\n",
    "\n",
    "Load the embeddings, FAISS index, and **chunk metadata** from `assignment-non-rag.ipynb`.\n",
    "\n",
    "**Important:** The FAISS index now points to **chunks** (sliding window segments), not full articles.\n",
    "- `chunks_metadata.json`: Contains chunk content, article_id, chunk_id\n",
    "- `article_embeddings.npy`: Embeddings for each chunk\n",
    "- `faiss_index.bin`: FAISS index mapping to chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa4a2a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading encoder model: intfloat/multilingual-e5-base\n",
      "âœ… Loaded 396 original articles\n",
      "âœ… Loaded 2325 chunks (from sliding window)\n",
      "âœ… Loaded embeddings: (2325, 768)\n",
      "âœ… Loaded FAISS index: 2325 vectors\n",
      "âœ… Encoder model ready\n",
      "âœ… Chunks and FAISS index are aligned\n",
      "âœ… Loaded 396 original articles\n",
      "âœ… Loaded 2325 chunks (from sliding window)\n",
      "âœ… Loaded embeddings: (2325, 768)\n",
      "âœ… Loaded FAISS index: 2325 vectors\n",
      "âœ… Encoder model ready\n",
      "âœ… Chunks and FAISS index are aligned\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Paths\n",
    "DATA_PATH = \"scraping_result/detik_sport_articles_cleaned.json\"\n",
    "EMBEDDINGS_PATH = \"embedding/article_embeddings.npy\"\n",
    "CHUNKS_PATH = \"embedding/chunks_metadata.json\"  # Chunk metadata from sliding window\n",
    "INDEX_PATH = \"faiss/faiss_index.bin\"\n",
    "MODEL_NAME = \"intfloat/multilingual-e5-base\"\n",
    "\n",
    "# Verify files exist\n",
    "required_files = [DATA_PATH, EMBEDDINGS_PATH, INDEX_PATH, CHUNKS_PATH]\n",
    "for file_path in required_files:\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"âŒ {file_path} not found. Run assignment-non-rag.ipynb first!\")\n",
    "\n",
    "# Load original articles (for reference)\n",
    "with open(DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    articles = json.load(f)\n",
    "df = pd.DataFrame(articles)\n",
    "df = df[df['content'].str.len() > 50].reset_index(drop=True)\n",
    "\n",
    "# Load chunk metadata (THIS IS WHAT FAISS INDEX POINTS TO)\n",
    "with open(CHUNKS_PATH, 'r', encoding='utf-8') as f:\n",
    "    chunks_metadata = json.load(f)\n",
    "df_chunks = pd.DataFrame(chunks_metadata)\n",
    "\n",
    "# Load embeddings and FAISS index\n",
    "embeddings = np.load(EMBEDDINGS_PATH)\n",
    "index = faiss.read_index(INDEX_PATH)\n",
    "\n",
    "# Load encoder model\n",
    "print(f\"Loading encoder model: {MODEL_NAME}\")\n",
    "encoder_model = SentenceTransformer(MODEL_NAME, device=\"cpu\")\n",
    "\n",
    "print(f\"âœ… Loaded {len(df)} original articles\")\n",
    "print(f\"âœ… Loaded {len(df_chunks)} chunks (from sliding window)\")\n",
    "print(f\"âœ… Loaded embeddings: {embeddings.shape}\")\n",
    "print(f\"âœ… Loaded FAISS index: {index.ntotal} vectors\")\n",
    "print(f\"âœ… Encoder model ready\")\n",
    "\n",
    "# Verify alignment\n",
    "if len(df_chunks) != index.ntotal:\n",
    "    print(f\"âš ï¸ WARNING: Chunk count ({len(df_chunks)}) != FAISS vectors ({index.ntotal})\")\n",
    "    print(\"   Please re-run assignment-non-rag.ipynb to regenerate embeddings and index\")\n",
    "else:\n",
    "    print(f\"âœ… Chunks and FAISS index are aligned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5719b8f6",
   "metadata": {},
   "source": [
    "## Step 1: Select Generation Component\n",
    "\n",
    "### Model Choice: **Qwen2.5:7b-instruct**\n",
    "\n",
    "**Key reasons:**\n",
    "1. **Better Indonesian understanding** - Our articles are in Indonesian\n",
    "2. **Larger context window** - Can include more retrieved passages\n",
    "3. **Better instruction following** - More likely to answer based on context only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "635cc0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ollama is running\n",
      "ğŸ“¦ Available models: ['qwen2.5:7b-instruct']\n",
      "âœ… Model 'qwen2.5:7b-instruct' is available\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Ollama API configuration\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "LLM_MODEL = \"qwen2.5:7b-instruct\"  # or \"qwen2.5:7b\" if instruct not available\n",
    "\n",
    "def check_ollama_status():\n",
    "    \"\"\"Check if Ollama is running and model is available\"\"\"\n",
    "    try:\n",
    "        # Check if Ollama is running\n",
    "        response = requests.get(f\"{OLLAMA_BASE_URL}/api/tags\")\n",
    "        if response.status_code == 200:\n",
    "            models = response.json().get('models', [])\n",
    "            model_names = [m['name'] for m in models]\n",
    "            print(f\"âœ… Ollama is running\")\n",
    "            print(f\"ğŸ“¦ Available models: {model_names}\")\n",
    "\n",
    "            # Check if our model is available\n",
    "            if any(LLM_MODEL in name for name in model_names):\n",
    "                print(f\"âœ… Model '{LLM_MODEL}' is available\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"âš ï¸ Model '{LLM_MODEL}' not found. Please run: ollama pull {LLM_MODEL}\")\n",
    "                return False\n",
    "        else:\n",
    "            print(\"âŒ Ollama API returned error\")\n",
    "            return False\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"âŒ Cannot connect to Ollama. Please start Ollama first: ollama serve\")\n",
    "        return False\n",
    "\n",
    "# Check Ollama status\n",
    "ollama_ready = check_ollama_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f06126",
   "metadata": {},
   "source": [
    "## Step 2: Build RAG Pipeline\n",
    "\n",
    "Components:\n",
    "1. **Retriever**: Reuse FAISS index from Part 1\n",
    "2. **Prompt Constructor**: Combine query + retrieved passages\n",
    "3. **Generator**: Ollama with Qwen2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729ee434",
   "metadata": {},
   "source": [
    "### Query Understanding with LLM\n",
    "\n",
    "Before sending the query to FAISS, we use the LLM to:\n",
    "1. **Extract key entities** (names, events, dates)\n",
    "2. **Reformulate** into a search-friendly query\n",
    "3. **Remove noise** (question words, filler words)\n",
    "\n",
    "**Flow:**\n",
    "```\n",
    "User Query â†’ LLM Query Understanding â†’ Optimized FAISS Query â†’ Retrieval â†’ Response Generation\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "879104ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def understand_query(user_query: str, verbose: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Use LLM to transform user query into an optimized search query for FAISS.\n",
    "\n",
    "    This extracts key entities and reformulates the query for better retrieval.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Kamu adalah query optimizer untuk sistem pencarian artikel olahraga Indonesia.\n",
    "\n",
    "    TUGAS: Ubah pertanyaan pengguna menjadi query pencarian yang optimal.\n",
    "\n",
    "    ATURAN:\n",
    "    1. Ekstrak entitas penting (nama pemain, tim, kompetisi, tanggal)\n",
    "    2. Hilangkan kata tanya (siapa, apa, mengapa, bagaimana, kapan)\n",
    "    3. Hilangkan kata penghubung yang tidak perlu\n",
    "    4. Gunakan kata kunci yang kemungkinan ada di artikel berita\n",
    "    5. Output HANYA query pencarian, tanpa penjelasan\n",
    "\n",
    "    CONTOH:\n",
    "    - Input: \"Siapa yang keluar sebagai Juara Dunia MotoGP musim 2025?\"\n",
    "    - Output: juara dunia MotoGP 2025\n",
    "\n",
    "    - Input: \"Mengapa Rashford kesulitan di Manchester United?\"\n",
    "    - Output: kondisi Rashford Manchester United masalah performa\n",
    "\n",
    "    - Input: \"Rangkum pencapaian tim bulutangkis Indonesia di ajang Australia Open 2025\"\n",
    "    - Output: tim bulutangkis Indonesia Australia Open 2025 pencapaian hasil\n",
    "\n",
    "    - Input: \"Bagaimana performa Timnas Indonesia di Piala AFF?\"\n",
    "    - Output: Timnas Indonesia Piala AFF performa hasil\n",
    "\n",
    "    PERTANYAAN PENGGUNA: {user_query}\n",
    "\n",
    "    QUERY PENCARIAN:\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{OLLAMA_BASE_URL}/api/generate\",\n",
    "            json={\n",
    "                \"model\": LLM_MODEL,\n",
    "                \"prompt\": prompt,\n",
    "                \"stream\": False,\n",
    "                \"options\": {\n",
    "                    \"temperature\": 0.1,  # Low temperature for consistent output\n",
    "                    \"num_predict\": 50    # Short output expected\n",
    "                }\n",
    "            },\n",
    "            timeout=60\n",
    "        )\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            optimized_query = response.json()['response'].strip()\n",
    "            # Clean up - remove any extra explanation the LLM might add\n",
    "            optimized_query = optimized_query.split('\\n')[0].strip()\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"ğŸ”„ Query Understanding:\")\n",
    "                print(f\"   Original: {user_query}\")\n",
    "                print(f\"   Optimized: {optimized_query}\")\n",
    "\n",
    "            return optimized_query\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"âš ï¸ Query understanding failed, using original query\")\n",
    "            return user_query\n",
    "\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"âš ï¸ Query understanding error: {e}, using original query\")\n",
    "        return user_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "898e1be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RAG pipeline functions defined (with Chunk-based Retrieval)\n"
     ]
    }
   ],
   "source": [
    "def retrieve_passages(query: str, top_k: int = 3, use_query_understanding: bool = True, verbose: bool = True) -> tuple[list[dict], str]:\n",
    "    \"\"\"\n",
    "    Retrieve relevant passages (chunks) using FAISS index.\n",
    "\n",
    "    Args:\n",
    "        query: User's original query\n",
    "        top_k: Number of passages to retrieve\n",
    "        use_query_understanding: Whether to use LLM to optimize query first\n",
    "        verbose: Print debug information\n",
    "\n",
    "    Returns:\n",
    "        tuple: (passages, optimized_query)\n",
    "    \"\"\"\n",
    "    # Step 1: Query Understanding (optional)\n",
    "    if use_query_understanding:\n",
    "        optimized_query = understand_query(query, verbose=verbose)\n",
    "    else:\n",
    "        optimized_query = query\n",
    "        if verbose:\n",
    "            print(f\"ğŸ” Using original query: {query}\")\n",
    "\n",
    "    # Step 2: Encode query with E5 prefix\n",
    "    query_with_prefix = f\"query: {optimized_query}\"\n",
    "    query_embedding = encoder_model.encode(\n",
    "        [query_with_prefix],\n",
    "        normalize_embeddings=True,\n",
    "        convert_to_numpy=True\n",
    "    )\n",
    "\n",
    "    # Step 3: Search FAISS index\n",
    "    scores, indices = index.search(query_embedding.astype('float32'), top_k)\n",
    "\n",
    "    # Step 4: Get passages from CHUNKS (not full articles!)\n",
    "    passages = []\n",
    "    for score, idx in zip(scores[0], indices[0]):\n",
    "        chunk = df_chunks.iloc[idx]\n",
    "        passages.append({\n",
    "            'title': chunk['title'],\n",
    "            'content': chunk['content'],  # This is chunk content, not full article\n",
    "            'date': chunk['date'],\n",
    "            'score': float(score),\n",
    "            'article_id': chunk['article_id'],\n",
    "            'chunk_id': chunk['chunk_id'],\n",
    "            'chunk_info': f\"Chunk {chunk['chunk_id']+1}/{chunk['total_chunks']}\"\n",
    "        })\n",
    "\n",
    "    return passages, optimized_query\n",
    "\n",
    "\n",
    "def construct_rag_prompt(query: str, passages: list[dict], max_content_len: int = 1000) -> str:\n",
    "    \"\"\"\n",
    "    Construct a prompt that combines the query with retrieved passages (chunks).\n",
    "    Instructs the LLM to answer based ONLY on the provided context.\n",
    "\n",
    "    Args:\n",
    "        query: User question (original, not optimized)\n",
    "        passages: Retrieved chunks from FAISS\n",
    "        max_content_len: Maximum characters per passage content\n",
    "    \"\"\"\n",
    "    # Format passages - chunks are already shorter, so we can use more content\n",
    "    context_parts = []\n",
    "    for i, p in enumerate(passages, 1):\n",
    "        content = p['content'][:max_content_len]\n",
    "        context_parts.append(f\"[{i}] {p['title']} ({p['chunk_info']})\\n{content}\")\n",
    "\n",
    "    context = \"\\n\\n\".join(context_parts)\n",
    "\n",
    "    prompt = f\"\"\"Jawab pertanyaan berdasarkan konteks berikut. Jika tidak ada informasi, katakan \"Tidak tersedia\".\n",
    "\n",
    "KONTEKS:\n",
    "{context}\n",
    "\n",
    "PERTANYAAN: {query}\n",
    "\n",
    "JAWABAN:\"\"\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def construct_non_rag_prompt(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Construct a prompt WITHOUT retrieved passages.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Jawab pertanyaan berikut dalam Bahasa Indonesia. PERTANYAAN: {query}\"\"\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "print(\"âœ… RAG pipeline functions defined (with Chunk-based Retrieval)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bdf3de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Generation functions defined (with Query Understanding support)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def generate_with_ollama(prompt: str, model: str = LLM_MODEL, timeout: int = 360) -> tuple[str, float]:\n",
    "    \"\"\"\n",
    "    Generate response using Ollama API.\n",
    "\n",
    "    Args:\n",
    "        prompt: The prompt to send to the LLM\n",
    "        model: Ollama model name\n",
    "        timeout: Request timeout in seconds (default 180 = 3 minutes)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (response_text, elapsed_time)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{OLLAMA_BASE_URL}/api/generate\",\n",
    "            json={\n",
    "                \"model\": model,\n",
    "                \"prompt\": prompt,\n",
    "                \"stream\": False,\n",
    "                \"options\": {\n",
    "                    \"temperature\": 0.3,\n",
    "                    \"top_p\": 0.9,\n",
    "                    \"num_predict\": 256\n",
    "                }\n",
    "            },\n",
    "            timeout=timeout\n",
    "        )\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            return response.json()['response'], elapsed\n",
    "        else:\n",
    "            return f\"Error: {response.status_code} - {response.text}\", elapsed\n",
    "    except requests.exceptions.Timeout:\n",
    "        elapsed = time.time() - start_time\n",
    "        return f\"Error: Request timed out after {elapsed:.0f}s. Try a smaller model or shorter context.\", elapsed\n",
    "    except Exception as e:\n",
    "        elapsed = time.time() - start_time\n",
    "        return f\"Error: {str(e)}\", elapsed\n",
    "\n",
    "\n",
    "def rag_query(query: str, top_k: int = 3, use_query_understanding: bool = True, verbose: bool = True) -> dict:\n",
    "    \"\"\"\n",
    "    Complete RAG pipeline: Query Understanding â†’ Retrieve â†’ Construct Prompt â†’ Generate\n",
    "\n",
    "    Args:\n",
    "        query: User's original query\n",
    "        top_k: Number of passages to retrieve\n",
    "        use_query_understanding: Whether to use LLM to optimize query for FAISS\n",
    "        verbose: Print debug information\n",
    "    \"\"\"\n",
    "    # Step 1: Retrieve relevant passages (with optional query understanding)\n",
    "    passages, optimized_query = retrieve_passages(\n",
    "        query,\n",
    "        top_k=top_k,\n",
    "        use_query_understanding=use_query_understanding,\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"ğŸ“š Retrieved {len(passages)} passages:\")\n",
    "        for i, p in enumerate(passages, 1):\n",
    "            print(f\"   {i}. [{p['score']:.4f}] {p['title']}\")\n",
    "        print()\n",
    "\n",
    "    # Step 2: Construct RAG prompt (use ORIGINAL query for response generation)\n",
    "    rag_prompt = construct_rag_prompt(query, passages)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"ğŸ“Š Prompt: {len(rag_prompt)} chars (~{len(rag_prompt)//4} tokens)\")\n",
    "        print(\"ğŸ¤– Generating RAG response...\")\n",
    "\n",
    "    # Step 3: Generate response\n",
    "    rag_response, elapsed = generate_with_ollama(rag_prompt)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"   â±ï¸ Generated in {elapsed:.1f}s\")\n",
    "\n",
    "    return {\n",
    "        'query': query,\n",
    "        'optimized_query': optimized_query,\n",
    "        'passages': passages,\n",
    "        'rag_response': rag_response,\n",
    "        'rag_prompt': rag_prompt,\n",
    "        'elapsed': elapsed\n",
    "    }\n",
    "\n",
    "\n",
    "def non_rag_query(query: str, verbose: bool = True) -> dict:\n",
    "    \"\"\"\n",
    "    Generate response WITHOUT retrieval (for comparison)\n",
    "    \"\"\"\n",
    "    prompt = construct_non_rag_prompt(query)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"ğŸ” Query: {query}\")\n",
    "        print(\"ğŸ¤– Generating non-RAG response (no context)...\")\n",
    "\n",
    "    response, elapsed = generate_with_ollama(prompt)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"   â±ï¸ Generated in {elapsed:.1f}s\")\n",
    "\n",
    "    return {\n",
    "        'query': query,\n",
    "        'non_rag_response': response,\n",
    "        'elapsed': elapsed\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"âœ… Generation functions defined (with Query Understanding support)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd0403f",
   "metadata": {},
   "source": [
    "## Step 3: Evaluation\n",
    "\n",
    "Test the RAG system with different types of questions:\n",
    "1. **Factual queries** - Specific facts that should be in the articles\n",
    "2. **Conceptual understanding** - Questions requiring comprehension\n",
    "3. **Synthesis questions** - Questions requiring combining information from multiple sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b131af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Test Questions Defined:\n",
      "\n",
      "FACTUAL:\n",
      "   1. Siapa pelatih baru Timnas Indonesia?\n",
      "   2. Berapa gol yang dicetak Ronaldo di Piala Dunia 2026?\n",
      "   3. Kapan Barcelona membeli pemain baru terakhir kali?\n",
      "\n",
      "CONCEPTUAL:\n",
      "   1. Mengapa Manchester United mengalami masalah performa musim ini?\n",
      "   2. Apa alasan Rashford kesulitan di Manchester United?\n",
      "   3. Bagaimana kondisi klasemen Liga Inggris saat ini?\n",
      "\n",
      "SYNTHESIS:\n",
      "   1. Bandingkan performa Ronaldo dan pemain bintang lainnya di kompetisi internasional\n",
      "   2. Apa dampak pergantian pelatih terhadap performa tim-tim besar Eropa?\n",
      "   3. Bagaimana situasi transfer pemain di liga-liga top Eropa?\n"
     ]
    }
   ],
   "source": [
    "# Define test questions for different categories\n",
    "test_questions = {\n",
    "    \"factual\": [\n",
    "        \"Siapa pelatih baru Timnas Indonesia?\",\n",
    "        \"Berapa gol yang dicetak Ronaldo di Piala Dunia 2026?\",\n",
    "        \"Kapan Barcelona membeli pemain baru terakhir kali?\"\n",
    "    ],\n",
    "    \"conceptual\": [\n",
    "        \"Mengapa Manchester United mengalami masalah performa musim ini?\",\n",
    "        \"Apa alasan Rashford kesulitan di Manchester United?\",\n",
    "        \"Bagaimana kondisi klasemen Liga Inggris saat ini?\"\n",
    "    ],\n",
    "    \"synthesis\": [\n",
    "        \"Bandingkan performa Ronaldo dan pemain bintang lainnya di kompetisi internasional\",\n",
    "        \"Apa dampak pergantian pelatih terhadap performa tim-tim besar Eropa?\",\n",
    "        \"Bagaimana situasi transfer pemain di liga-liga top Eropa?\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"ğŸ“‹ Test Questions Defined:\")\n",
    "for category, questions in test_questions.items():\n",
    "    print(f\"\\n{category.upper()}:\")\n",
    "    for i, q in enumerate(questions, 1):\n",
    "        print(f\"   {i}. {q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41d0536",
   "metadata": {},
   "source": [
    "### Test 1: Factual Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aceeb0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Query Understanding:\n",
      "   Original: Siapa yang keluar sebagai Juara Dunia MotoGP musim 2025?\n",
      "   Optimized: juara dunia MotoGP 2025\n"
     ]
    }
   ],
   "source": [
    "# DEBUG: See what's being sent to the LLM (UNTUK DEBUGGING AJA)\n",
    "test_query = \"Siapa yang keluar sebagai Juara Dunia MotoGP musim 2025?\"\n",
    "passages, optimized_query = retrieve_passages(test_query, top_k=3, use_query_understanding=True)\n",
    "rag_prompt = construct_rag_prompt(test_query, passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8fbab15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š PROMPT STATISTICS:\n",
      "   - Original query: Siapa yang keluar sebagai Juara Dunia MotoGP musim 2025?\n",
      "   - Optimized query: juara dunia MotoGP 2025\n",
      "   - Total characters: 1833\n",
      "   - Estimated tokens: ~458 tokens\n",
      "   - Number of passages: 3\n",
      "\n",
      "ğŸ“ FULL PROMPT SENT TO LLM:\n",
      "================================================================================\n",
      "Jawab pertanyaan berdasarkan konteks berikut. Jika tidak ada informasi, katakan \"Tidak tersedia\".\n",
      "\n",
      "KONTEKS:\n",
      "[1] Jadwal MotoGP Valencia 2025: Bakal Ada 7 Pemenang Berbeda Beruntun? (Chunk 2/6)\n",
      "oGP 2025, race di Ricardo Tormo, Valencia, pada akhir pekan ini bakal menjadi balapan penutup musim. Saat ini Marc Marquez sudah dipastikan menjadi juara dunia MotoGP 2025 . Adik kandungnya, Alex Marquez, juga sudah mengunci posisi kedua di klasemen MotoGP 2025 . Secara matematis, posisi itu menjadi rebutan Marco Bezzecchi dan Francesco 'Pecco' Bagnaia . Saat ini Bezz berada di posisi yang lebih baik ketimbang Pecco untuk bisa memastikan posisi ketiga di akhir musim.\n",
      "\n",
      "[2] Klasemen Akhir MotoGP 2025: Marc Marquez No 1, Disusul Alex dan Bezzecchi (Chunk 1/6)\n",
      "Jakarta - Tuntas sudah MotoGP 2025 usai balapan penutup musim di Valencia. Marquez bersaudara mengisi dua posisi teratas klasemen MotoGP , disusul Marco Bezzecchi yang melengkapi tiga besar. Marc Marquez mengakhiri MotoGP 2025 dengan 545 poin. Setelah mengunci gelar juara dunia MotoGP 2025 di Motegi, rider Ducati itu lantas crash di Mandalika dan absen di empat balapan terakhir. Posisi runner-up ditempati oleh Alex Marquez .\n",
      "\n",
      "[3] Link Live Streaming MotoGP Portugal 2025: Race Mulai Pukul 20.00 WIB (Chunk 2/3)\n",
      "Portugal pada akhir pekan ini akan ada MotoGP Valencia 2025 sebagai seri pamungkas pada pekan depan. Sejauh ini Marc Marquez sudah dipastikan juara dunia MotoGP 2025. Predikat runner-up di posisi klasemen MotoGP 2025 pun sudah mutlak menjadi adiknya, Alex Marquez. Salah satu persaingan yang masih tersisa adalah sengitnya perebutan posisi ketiga. Secara khusus di antara Marco Bezzecchi dengan Francesco Bagnaia. Bezzecchi untuk sementara menempati peringkat ketiga dengan 298 poin.\n",
      "\n",
      "PERTANYAAN: Siapa yang keluar sebagai Juara Dunia MotoGP musim 2025?\n",
      "\n",
      "JAWABAN:\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Ini buat debugging juga\n",
    "print(\"ğŸ“Š PROMPT STATISTICS:\")\n",
    "print(f\"   - Original query: {test_query}\")\n",
    "print(f\"   - Optimized query: {optimized_query}\")\n",
    "print(f\"   - Total characters: {len(rag_prompt)}\")\n",
    "print(f\"   - Estimated tokens: ~{len(rag_prompt) // 4} tokens\")\n",
    "print(f\"   - Number of passages: {len(passages)}\")\n",
    "print()\n",
    "print(\"ğŸ“ FULL PROMPT SENT TO LLM:\")\n",
    "print(\"=\" * 80)\n",
    "print(rag_prompt)\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f1652ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Query Understanding:\n",
      "   Original: Apa julukan yang dimiliki oleh klub sepakbola Ajax Amsterdam?\n",
      "   Optimized: juulan ajax amsterdam klub sepakbola julukan\n",
      "ğŸ“š Retrieved 3 passages:\n",
      "   1. [0.8892] Profil Ajax: Filosofi Total Football dan Pabrik Bintang Dunia\n",
      "   2. [0.8693] Profil Ajax: Filosofi Total Football dan Pabrik Bintang Dunia\n",
      "   3. [0.8646] Profil Ajax: Filosofi Total Football dan Pabrik Bintang Dunia\n",
      "\n",
      "ğŸ“Š Prompt: 1685 chars (~421 tokens)\n",
      "ğŸ¤– Generating RAG response...\n",
      "   â±ï¸ Generated in 54.0s\n",
      "ğŸ” Query: Apa julukan yang dimiliki oleh klub sepakbola Ajax Amsterdam?\n",
      "ğŸ¤– Generating non-RAG response (no context)...\n",
      "   â±ï¸ Generated in 54.0s\n",
      "ğŸ” Query: Apa julukan yang dimiliki oleh klub sepakbola Ajax Amsterdam?\n",
      "ğŸ¤– Generating non-RAG response (no context)...\n",
      "   â±ï¸ Generated in 23.0s\n",
      "   â±ï¸ Generated in 23.0s\n"
     ]
    }
   ],
   "source": [
    "# Factual Query Test\n",
    "factual_query = \"Apa julukan yang dimiliki oleh klub sepakbola Ajax Amsterdam?\"\n",
    "\n",
    "# RAG Response\n",
    "factual_rag_result = rag_query(factual_query, top_k=3)\n",
    "\n",
    "# Non-RAG Response\n",
    "factual_non_rag_result = non_rag_query(factual_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beb27703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FACTUAL QUERY TEST\n",
      "================================================================================\n",
      "\n",
      "ğŸ“— RAG RESPONSE:\n",
      "----------------------------------------\n",
      "Julukan yang dimiliki oleh klub sepakbola Ajax Amsterdam antara lain de Joden, Lucky Ajax, the Lancers, dan de Godenzonen.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“• NON-RAG RESPONSE:\n",
      "----------------------------------------\n",
      "Klub sepakbola Ajax Amsterdam memiliki beberapa julukan, namun julukan terkenal dan paling umum adalah \"Tim Raksasa\" atau dalam bahasa Indonesia disebut \"Tim Orang Besar\". Julukan ini berasal dari bahasa Belanda yang berarti \"Giant Club\", di mana \"giant\" berarti raksasa.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"FACTUAL QUERY TEST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ“— RAG RESPONSE:\")\n",
    "print(\"-\" * 40)\n",
    "print(factual_rag_result['rag_response'])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ“• NON-RAG RESPONSE:\")\n",
    "print(\"-\" * 40)\n",
    "print(factual_non_rag_result['non_rag_response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc84c22",
   "metadata": {},
   "source": [
    "### Test 2: Conceptual Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44cc449f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Query Understanding:\n",
      "   Original: Mengapa Rashford kesulitan di Manchester United?\n",
      "   Optimized: kondisi Rashford Manchester United masalah performa\n",
      "ğŸ“š Retrieved 3 passages:\n",
      "   1. [0.8790] Deco: Rashford Menderita di MU\n",
      "   2. [0.8707] Deco: Rashford Menderita di MU\n",
      "   3. [0.8625] Deco: Rashford Menderita di MU\n",
      "\n",
      "ğŸ“Š Prompt: 1608 chars (~402 tokens)\n",
      "ğŸ¤– Generating RAG response...\n",
      "   â±ï¸ Generated in 77.8s\n",
      "ğŸ” Query: Mengapa Rashford kesulitan di Manchester United?\n",
      "ğŸ¤– Generating non-RAG response (no context)...\n",
      "   â±ï¸ Generated in 77.8s\n",
      "ğŸ” Query: Mengapa Rashford kesulitan di Manchester United?\n",
      "ğŸ¤– Generating non-RAG response (no context)...\n",
      "   â±ï¸ Generated in 55.1s\n",
      "   â±ï¸ Generated in 55.1s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Conceptual Query Test\n",
    "conceptual_query = \"Mengapa Rashford kesulitan di Manchester United?\"\n",
    "\n",
    "# RAG Response\n",
    "conceptual_rag_result = rag_query(conceptual_query, top_k=3)\n",
    "\n",
    "# Non-RAG Response\n",
    "conceptual_non_rag_result = non_rag_query(conceptual_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "263e807a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CONCEPTUAL UNDERSTANDING TEST\n",
      "================================================================================\n",
      "\n",
      "ğŸ“— RAG RESPONSE:\n",
      "----------------------------------------\n",
      "Rashford kesulitan di Manchester United karena mengalami perubahan generasi di tim tersebut. Menurut Deco, ini tidak mudah bagi seorang pemain penting yang memiliki banyak tanggung jawab. Selama lima tahun terakhir, United kesulitan membangun kembali tim agar lebih kuat.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“• NON-RAG RESPONSE:\n",
      "----------------------------------------\n",
      "Rashford mengalami beberapa tantangan di Manchester United yang dapat mempengaruhi performa dan posisinya sebagai pemain utama. Berikut beberapa alasan mengapa Rashford kesulitan di Manchester United:\n",
      "\n",
      "1. Persaingan Ketat: Manchester United memiliki banyak pemain berkualitas di posisi serang, termasuk Marcus Rashford sendiri. Hal ini membuat persaingan untuk tempat bermain menjadi sangat ketat.\n",
      "\n",
      "2. Kekuatan Mental: Beberapa laporan menyebutkan bahwa Rashford mengalami masalah kepercayaan diri dan tekanan mental yang cukup tinggi, terutama setelah beberapa musim tanpa gelar besar.\n",
      "\n",
      "3. Perubahan Taktik: Manajer sebelumnya, Ole Gunnar SolskjÃ¦r, sering kali memainkan skema taktis yang berbeda dari yang digunakan oleh manajer masa lalu. Hal ini dapat membuat Rashford kesulitan menyesuaikan diri.\n",
      "\n",
      "4. Cedera: Rashford pernah mengalami beberapa cedera serius yang membatasi ketersediaannya untuk bermain dan mempengaruhi performanya saat\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"CONCEPTUAL UNDERSTANDING TEST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ“— RAG RESPONSE:\")\n",
    "print(\"-\" * 40)\n",
    "print(conceptual_rag_result['rag_response'])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ“• NON-RAG RESPONSE:\")\n",
    "print(\"-\" * 40)\n",
    "print(conceptual_non_rag_result['non_rag_response'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6400f38c",
   "metadata": {},
   "source": [
    "### Test 3: Synthesis Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3616f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Query Understanding:\n",
      "   Original: Rangkum pencapaian tim bulutangkis Indonesia di ajang Australia Open 2025.\n",
      "   Optimized: tim bulutangkis Indonesia Australia Open 2025 pencapaian hasil\n",
      "ğŸ“š Retrieved 5 passages:\n",
      "   1. [0.8906] Hasil Lengkap Australia Open 2025: RI Raih 2 Gelar Juara!\n",
      "   2. [0.8847] PBSI-BNI Beri Dukungan Penuh untuk Atlet RI di Final Australia Open 2025\n",
      "   3. [0.8728] PBSI-BNI Beri Dukungan Penuh untuk Atlet RI di Final Australia Open 2025\n",
      "   4. [0.8682] Australia Open 2025: Hasil Pebulutangkis RI Hari Ini, Jojo Belum Main\n",
      "   5. [0.8672] Australia Open 2025: Hasil Pebulutangkis RI Hari Ini, Jojo Belum Main\n",
      "\n",
      "ğŸ“Š Prompt: 2820 chars (~705 tokens)\n",
      "ğŸ¤– Generating RAG response...\n",
      "   â±ï¸ Generated in 172.9s\n",
      "ğŸ” Query: Rangkum pencapaian tim bulutangkis Indonesia di ajang Australia Open 2025.\n",
      "ğŸ¤– Generating non-RAG response (no context)...\n",
      "   â±ï¸ Generated in 172.9s\n",
      "ğŸ” Query: Rangkum pencapaian tim bulutangkis Indonesia di ajang Australia Open 2025.\n",
      "ğŸ¤– Generating non-RAG response (no context)...\n",
      "   â±ï¸ Generated in 57.6s\n",
      "   â±ï¸ Generated in 57.6s\n"
     ]
    }
   ],
   "source": [
    "# Synthesis Query Test\n",
    "synthesis_query = \"Rangkum pencapaian tim bulutangkis Indonesia di ajang Australia Open 2025.\"\n",
    "\n",
    "# RAG Response\n",
    "synthesis_rag_result = rag_query(synthesis_query, top_k=5)  # More passages for synthesis\n",
    "\n",
    "# Non-RAG Response\n",
    "synthesis_non_rag_result = non_rag_query(synthesis_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8c55a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SYNTHESIS QUESTION TEST\n",
      "================================================================================\n",
      "\n",
      "ğŸ“— RAG RESPONSE:\n",
      "----------------------------------------\n",
      "Tim bulutangkis Indonesia mencapai prestasi luar biasa di ajang BWF Super 500 Australia Open 2025. Dua partai final nasional terjadi, yaitu dalam nomor ganda putri dan ganda putra. Meskipun informasi spesifik tentang pemenang final tidak disebutkan, dapat diketahui bahwa Indonesia meraih dua gelar juara dari rangkaian pertandingan final tersebut.\n",
      "\n",
      "Selain pencapaian di final, beberapa atlet Indonesia juga berhasil lolos ke babak 32 besar. Hasil yang dicapai antara lain:\n",
      "\n",
      "- Sabar Karyaman Gutama/Moh. Reza Pahlevi Isfahani menang atas Hiroki Midorikawa/Kyohei Yamashita\n",
      "- Alwi Farhan memenangkan pertandingan dengan withdraw lawannya \n",
      "- Putri Kusuma Wardani mengalahkan Sung Shuo Yun dengan skor 21-12, 21-8\n",
      "- Adnan Maulana/Indah Cahya Sari Jamil menang atas Edward Lau/Shaunna Li dengan skor 21-14,\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“• NON-RAG RESPONSE:\n",
      "----------------------------------------\n",
      "Maaf, untuk memberikan rangkuman tentang pencapaian tim bulutangkis Indonesia di Australian Open 2025, saya perlu mengecek informasi terbaru dan akurat karena sampai saat ini data tersebut belum tersedia. Namun, berdasarkan pola sebelumnya, beberapa aspek yang biasanya menjadi fokus dalam rangkuman pencapaian tim bulutangkis Indonesia di Australian Open antara lain:\n",
      "\n",
      "1. **Pencapaian Pemain Individual**: Biasanya akan disebutkan nama-nama pemain Indonesia yang berhasil lolos ke babak kualifikasi atau masuk ke babak utama, serta hasil-hasil pertandingan mereka.\n",
      "\n",
      "2. **Hasil Terbaik**: Informasi tentang pemain Indonesia yang mencapai tahap final atau semifinal di Australian Open akan disebutkan.\n",
      "\n",
      "3. **Prestasi Tim**: Pencapaian tim ganda putra dan putri Indonesia, termasuk babak kualifikasi dan hasil pertandingan utama.\n",
      "\n",
      "4. **Analisis Performa**: Biasanya akan ada analisis tentang performa pemain Indonesia, strategi yang digunakan, serta faktor-faktor yang mempengaru\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SYNTHESIS QUESTION TEST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ“— RAG RESPONSE:\")\n",
    "print(\"-\" * 40)\n",
    "print(synthesis_rag_result['rag_response'])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ“• NON-RAG RESPONSE:\")\n",
    "print(\"-\" * 40)\n",
    "print(synthesis_non_rag_result['non_rag_response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1087191c",
   "metadata": {},
   "source": [
    "### Manual Evaluation\n",
    "\n",
    "Use the cell below to manually score the responses. Fill in scores 1-5 for each criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02c73e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Evaluation Scores (Fill in after reviewing responses above)\n",
    "# Score range: 1 (Poor) to 5 (Excellent)\n",
    "\n",
    "manual_scores = {\n",
    "    \"RAG\": {\n",
    "        \"Factual\": {\n",
    "            \"groundedness\": 5,      # Is answer based on retrieved passages?\n",
    "            \"factual_accuracy\": 4,  # Are facts correct?\n",
    "            \"no_hallucination\": 3,  # Does it avoid making things up?\n",
    "            \"relevance\": 5,         # Does it answer the question?\n",
    "            \"completeness\": 5       # Is the answer complete?\n",
    "        },\n",
    "        \"Conceptual\": {\n",
    "            \"groundedness\": 5,\n",
    "            \"factual_accuracy\": 5,\n",
    "            \"no_hallucination\": 3,\n",
    "            \"relevance\": 4,\n",
    "            \"completeness\": 5\n",
    "        },\n",
    "        \"Synthesis\": {\n",
    "            \"groundedness\": 5,\n",
    "            \"factual_accuracy\": 5,\n",
    "            \"no_hallucination\": 5,\n",
    "            \"relevance\": 5,\n",
    "            \"completeness\": 5\n",
    "        }\n",
    "    },\n",
    "    \"Non-RAG\": {\n",
    "        \"Factual\": {\n",
    "            \"groundedness\": 5,\n",
    "            \"factual_accuracy\": 5,\n",
    "            \"no_hallucination\": 5,\n",
    "            \"relevance\": 5,\n",
    "            \"completeness\": 5\n",
    "        },\n",
    "        \"Conceptual\": {\n",
    "            \"groundedness\": 5,\n",
    "            \"factual_accuracy\": 2,\n",
    "            \"no_hallucination\": 3,\n",
    "            \"relevance\": 5,\n",
    "            \"completeness\": 4\n",
    "        },\n",
    "        \"Synthesis\": {\n",
    "            \"groundedness\": 5,\n",
    "            \"factual_accuracy\": 3,\n",
    "            \"no_hallucination\": 4,\n",
    "            \"relevance\": 4,\n",
    "            \"completeness\": 5\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"ğŸ“ Manual Evaluation Template\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nInstructions:\")\n",
    "print(\"1. Review the RAG and Non-RAG responses from the tests above\")\n",
    "print(\"2. Fill in scores (1-5) in the manual_scores dictionary\")\n",
    "print(\"3. Run the next cell to see the summary\")\n",
    "print(\"\\nScoring Guide:\")\n",
    "print(\"  1 = Poor       - Completely wrong or irrelevant\")\n",
    "print(\"  2 = Below Avg  - Major issues\")\n",
    "print(\"  3 = Average    - Acceptable but with issues\")\n",
    "print(\"  4 = Good       - Mostly correct with minor issues\")\n",
    "print(\"  5 = Excellent  - Fully correct and complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0a536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_evaluation_summary(scores: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate summary statistics from manual evaluation scores.\n",
    "    \"\"\"\n",
    "    criteria = [\"groundedness\", \"factual_accuracy\", \"no_hallucination\", \"relevance\", \"completeness\"]\n",
    "\n",
    "    summary = []\n",
    "    for system in [\"RAG\", \"Non-RAG\"]:\n",
    "        system_scores = scores[system]\n",
    "\n",
    "        # Calculate averages across all queries\n",
    "        avg_scores = {c: [] for c in criteria}\n",
    "\n",
    "        for query_scores in system_scores.values():\n",
    "            for criterion, score in query_scores.items():\n",
    "                if score > 0:  # Only count filled scores\n",
    "                    avg_scores[criterion].append(score)\n",
    "\n",
    "        # Calculate final averages\n",
    "        final_scores = {}\n",
    "        for criterion, scores_list in avg_scores.items():\n",
    "            final_scores[criterion] = sum(scores_list) / len(scores_list) if scores_list else 0\n",
    "\n",
    "        overall = sum(final_scores.values()) / len(final_scores) if any(final_scores.values()) else 0\n",
    "\n",
    "        summary.append({\n",
    "            \"System\": system,\n",
    "            \"Groundedness\": final_scores[\"groundedness\"],\n",
    "            \"Factual Acc.\": final_scores[\"factual_accuracy\"],\n",
    "            \"No Halluc.\": final_scores[\"no_hallucination\"],\n",
    "            \"Relevance\": final_scores[\"relevance\"],\n",
    "            \"Completeness\": final_scores[\"completeness\"],\n",
    "            \"Overall\": overall\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(summary)\n",
    "\n",
    "\n",
    "# Calculate and display summary\n",
    "print(\"ğŸ“Š Evaluation Summary\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check if scores have been filled\n",
    "has_scores = any(\n",
    "    score > 0\n",
    "    for system in manual_scores.values()\n",
    "    for query in system.values()\n",
    "    for score in query.values()\n",
    ")\n",
    "\n",
    "if not has_scores:\n",
    "    print(\"âš ï¸ No scores filled yet. Please fill in manual_scores above and re-run this cell.\")\n",
    "else:\n",
    "    summary_df = calculate_evaluation_summary(manual_scores)\n",
    "    print(summary_df.to_string(index=False))\n",
    "\n",
    "    # Calculate winner for each criterion\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"ğŸ† Winner by Criterion:\")\n",
    "    for col in summary_df.columns[1:]:\n",
    "        rag_score = summary_df.loc[summary_df['System'] == 'RAG', col].values[0]\n",
    "        non_rag_score = summary_df.loc[summary_df['System'] == 'Non-RAG', col].values[0]\n",
    "        if rag_score > non_rag_score:\n",
    "            print(f\"   {col}: RAG wins ({rag_score:.2f} vs {non_rag_score:.2f})\")\n",
    "        elif non_rag_score > rag_score:\n",
    "            print(f\"   {col}: Non-RAG wins ({non_rag_score:.2f} vs {rag_score:.2f})\")\n",
    "        else:\n",
    "            print(f\"   {col}: Tie ({rag_score:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7acd15",
   "metadata": {},
   "source": [
    "## RAG System Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                     RAG SYSTEM PIPELINE                         â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                 â”‚\n",
    "â”‚   User Query                                                    â”‚\n",
    "â”‚       â”‚                                                         â”‚\n",
    "â”‚       â–¼                                                         â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚\n",
    "â”‚   â”‚  QUERY UNDERSTANDING (Ollama)       â”‚                       â”‚\n",
    "â”‚   â”‚  - Extract entities                 â”‚                       â”‚\n",
    "â”‚   â”‚  - Optimize for search              â”‚                       â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚\n",
    "â”‚       â”‚                                                         â”‚\n",
    "â”‚       â–¼                                                         â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚\n",
    "â”‚   â”‚  RETRIEVER (from assignment-non-rag)â”‚                       â”‚\n",
    "â”‚   â”‚  - Multilingual E5 Encoder          â”‚                       â”‚\n",
    "â”‚   â”‚  - FAISS Vector Index               â”‚                       â”‚\n",
    "â”‚   â”‚  - Returns CHUNKS (not full docs)   â”‚  â† Sliding Window     â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    500 chars, 100 overlap\n",
    "â”‚       â”‚                                                         â”‚\n",
    "â”‚       â–¼                                                         â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚\n",
    "â”‚   â”‚  PROMPT CONSTRUCTOR                 â”‚                       â”‚\n",
    "â”‚   â”‚  - Combine Query + Chunks           â”‚                       â”‚\n",
    "â”‚   â”‚  - Add Grounding Instructions       â”‚                       â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚\n",
    "â”‚       â”‚                                                         â”‚\n",
    "â”‚       â–¼                                                         â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚\n",
    "â”‚   â”‚  GENERATOR (Ollama)                 â”‚                       â”‚\n",
    "â”‚   â”‚  - Qwen2.5-7B-Instruct              â”‚                       â”‚\n",
    "â”‚   â”‚  - Grounded Response Generation     â”‚                       â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚\n",
    "â”‚       â”‚                                                         â”‚\n",
    "â”‚       â–¼                                                         â”‚\n",
    "â”‚   Grounded Response                                             â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-sport-articles (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
